############################## GLOBAL REQUIRES PACKS ##########################################

library(dplyr)
library(lubridate)
library(fBasics)
library(xgboost)
library(tidyverse)
library(broom)
library(jsonlite)


install.packages()


############################## GLOBAL PARAMETERS ##########################################

# DATA PARAMETER
# Parametric Keys 
keys <- list(
  "key_wkd_q_index" =  c("V8", "Week_Year", "Day_Week"),
  "key_dw_q_index" = c("V8", "Day_Week"),
  "key_wkday_index" = c("V8", "Weekday_Month"),
  "key_rd_index" = c("V8", "Rest_3day"),
  "key_hd_index" = c("V8", "Kor_Holiday"))


index_name <- list(
  "wkd_q_index" = "WKD_Q_Index",
  "dw_q_index" = "DW_Q_Index",
  "wkday_q_index" = "WKDay_Q_Index",
  "wkd_nt_index" = "WKD_NT_Index",
  "wkd_rt_index" = "WKD_RT_Index",
  "rd_index" = "Rest_Index",
  "hd_index" = "Holi_Index")



# TRAIN PARAMETERS
basic_column_list <- c(
  "V1", "V8", "Tot_Sum_Q", "Mean_Price", "Weekday_Month",
  "Day_Week", "Week_Year", "Kor_Holiday", "Rest_3day", "WKD_Q_Index",
  "WKDay_Q_Index", "WKD_NT_Index",  "WKD_RT_Index",  "Rest_Index", 
  "Holi_Index")


elimination_col_list <- c("V1", "PEQ_Cluster")



############################### DATA PREPROCESSING FUNCTIONS #################################


# calculate time vars
calculate_time_variable_v2 <- function(x, kor_holidays = NULL){
  # prevent package collision 
  if("data.table" %in% (.packages())){
    detach("package:data.table", unload=TRUE)
  }
  require(lubridate)
  
  if(is.null(kor_holidays)){
    korea_holidays <- c('2016-01-01', '2016-02-07', '2016-02-08', '2016-02-09', '2016-02-10', 
                        '2016-03-01', '2016-04-13', '2016-05-05', '2016-05-14', '2016-06-06',
                        '2016-08-15', '2016-09-14', '2016-09-15', '2016-09-16', '2016-10-03', 
                        '2016-12-25', 
                        '2017-01-01', '2017-01-27', '2017-01-28', '2017-01-29', '2017-01-30',
                        '2017-03-01', '2017-05-03', '2017-05-05', '2017-06-06', '2017-08-15',
                        '2017-10-03', '2017-10-04', '2017-10-05', '2017-10-06', '2017-10-09',
                        '2017-12-25', 
                        '2018-01-01', '2018-02-15', '2018-02-16', '2018-02-17', '2018-03-01', 
                        '2018-05-05', '2018-05-06', '2018-05-07', '2018-05-22', '2018-06-06', 
                        '2018-06-13', '2018-08-15', '2018-09-23', '2018-09-24', '2018-09-25', 
                        '2018-09-26', '2018-10-03', '2018-10-09', '2018-12-25',
                        '2019-01-01', '2019-02-04', '2019-02-05', '2019-02-06', '2019-03-01',
                        '2019-05-05', '2019-05-12', '2019-06-06', '2019-08-15', '2019-09-12',
                        '2019-09-13', '2019-09-14', '2019-10-03', '2019-10-09', '2019-12-25')
  }
  
  korea_holidays <- as.Date(korea_holidays)
  
  # 1년 중 일자, y-day (1일 ~ 365일) / 일자변수 # 1~365
  # x$YDay <- lubridate::yday(x$V1)
  
  # 각 분기별 일자 4달별로 나뉘어서, 들어감  # 1~100정도?
  # x$QDay <- lubridate::qday(x$V1)  
  
  #월 (1월~12월)  1 ~12 
  # x$Month <- lubridate::month(x$V1, abbr = T)
  
  # 각 월별 일자, 1일 2일 3일 ~ 31일 # 1~31 
  # x$MDay <- lubridate::mday(x$V1) 
  
  # weekday of month (각 월의 몇주차))
  x$Weekday_Month <- ceiling(lubridate::day(x$V1)/7)
  

  # 분기숫자 Q1, Q2, Q3, Q4
  # x$Quarter <- quarters(x$V1)
  
  # 요일 변환
  x$Day_Week <- lubridate::wday(x$V1, label = T, abbr = T,
                                week_start = getOption("lubridate.week.start", 7))
  
  # 주차 (1주차, 2주차, 3주차) 1~52주 - 이미 있는 데이터
  
  
  x$Week_Year <- lubridate::week(x$V1)
  # 이미 있는 주차(V44) 데이터 활용 
  # x$Week_Year <- as.factor(x$V44)
  
  # 휴일구분코드(V45)
  # x$Holiday_Code <- as.factor(x$V45)
  
  # 점포 휴일여부(V46) 
  # x$Jumpo_holiday <- as.factor(x$V46)
  
  # 한국 휴일 포함 여부
  x$Kor_Holiday <- as.factor(ifelse(x$V1 %in% korea_holidays, 1, 0))
  # x <- subset(x, select = c(-V44, -V45, -V46))
  return(x)
}


# rest day 
before_after_3days_of_restday_v2 <- function(x, target_data, given_rest_day = NULL){
  
  # is Given Rest Day! 
  if(!is.null(given_rest_day)){
    rest_day <- as.Date(given_rest_day) }
  
  else{
    # else Don't Give Rest Day!
    # parst rest day wieh Rule 
    rest_day <- unique(order_table[x$Day_Week == "Sun" & 
                                     (x$Weekday_Month == "1" | 
                                        x$Weekday_Month == "3"),]$V1)
    rest_day <- as.Date(rest_day)
  }
  
  # before after 3days of rest_day 
  # rest_days <- mapply(c, rest_day - 3, rest_day - 2, rest_day - 1, rest_day + 1, SIMPLIFY = F)
  rest_days <- mapply(c, rest_day - 3, rest_day - 2, rest_day + 1, SIMPLIFY = F)
  # rest_days <- mapply(c, rest_day - 3, rest_day + 1, SIMPLIFY = F)
  
  # dataframe
  df_rest_days <- data.frame(V1 = as.Date(unlist(rest_days), origin = "1970-01-01"), Rest_3day = 1)
  
  return_x <- dplyr::left_join(target_data, df_rest_days)
  return_x$Rest_3day[is.na(return_x$Rest_3day)] <- 0
  print(sum(is.na(return_x)))
  return_x$Rest_3day <- as.factor(return_x$Rest_3day)
  return(return_x)
} 


# calculate time vars
calculate_time_variable_v1 <- function(x){
  # prevent package collision 
  if("data.table" %in% (.packages())){
    detach("package:data.table", unload=TRUE)
  }
  require(lubridate)
  # 2016~2019년 한국 휴일 (대체공휴일 포함, 주말 휴일포함, 연휴미포함)
  korea_holidays <- c('2016-01-01', '2016-02-07', '2016-02-08', '2016-02-09', '2016-02-10', 
                      '2016-03-01', '2016-04-13', '2016-05-05', '2016-05-14', '2016-06-06',
                      '2016-08-15', '2016-09-14', '2016-09-15', '2016-09-16', '2016-10-03', 
                      '2016-12-25', 
                      '2017-01-01', '2017-01-27', '2017-01-28', '2017-01-29', '2017-01-30',
                      '2017-03-01', '2017-05-03', '2017-05-05', '2017-06-06', '2017-08-15',
                      '2017-10-03', '2017-10-04', '2017-10-05', '2017-10-06', '2017-10-09',
                      '2017-12-25', 
                      '2018-01-01', '2018-02-15', '2018-02-16', '2018-02-17', '2018-03-01', 
                      '2018-05-05', '2018-05-06', '2018-05-07', '2018-05-22', '2018-06-06', 
                      '2018-06-13', '2018-08-15', '2018-09-23', '2018-09-24', '2018-09-25', 
                      '2018-09-26', '2018-10-03', '2018-10-09', '2018-12-25',
                      '2019-01-01', '2019-02-04', '2019-02-05', '2019-02-06', '2019-03-01',
                      '2019-05-05', '2019-05-12', '2019-06-06', '2019-08-15', '2019-09-12',
                      '2019-09-13', '2019-09-14', '2019-10-03', '2019-10-09', '2019-12-25')
  korea_holidays <- as.Date(korea_holidays)
  
  # 1년 중 일자, y-day (1일 ~ 365일) / 일자변수 # 1~365
  x$YDay <- lubridate::yday(x$V1)
  
  # 각 분기별 일자 4달별로 나뉘어서, 들어감  # 1~100정도?
  x$QDay <- lubridate::qday(x$V1)  
  
  #월 (1월~12월)  1 ~12 
  x$Month <- lubridate::month(x$V1, abbr = T)
  
  # 각 월별 일자, 1일 2일 3일 ~ 31일 # 1~31 
  x$MDay <- lubridate::mday(x$V1) 
  
  # weekday of month (각 월의 몇주차))
  x$Weekday_Month <- ceiling(day(x$V1)/7)
  
  # 분기숫자 Q1, Q2, Q3, Q4
  x$Quarter <- quarters(x$V1)
  
  # 요일 변환
  x$Day_Week <- lubridate::wday(x$V1, label = T, abbr = T,
                                week_start = getOption("lubridate.week.start", 7))
  
  # 주차 (1주차, 2주차, 3주차) 1~52주 - 이미 있는 데이터
  x$Week_Year <- week(x$V1)
  # 이미 있는 주차(V44) 데이터 활용 
  # x$Week_Year <- as.factor(x$V44)
  
  # 휴일구분코드(V45)
  # x$Holiday_Code <- as.factor(x$V45)
  
  # 점포 휴일여부(V46) 
  # x$Jumpo_holiday <- as.factor(x$V46)
  
  # 한국 휴일 포함 여부
  x$Kor_Holiday <- as.factor(ifelse(x$V1 %in% korea_holidays, 1, 0))
  # x <- subset(x, select = c(-V44, -V45, -V46))
  return(x)
}


# x - pos_date (real sales days)
# y - product or train1049 data <- appended target data
before_after_3days_of_restday <- function(x, target_data, given_rest_day = NULL){
  
  # is Given Rest Day! 
  if(!is.null(given_rest_day)){
    rest_day <- as.Date(given_rest_day)
    
    # else Don't Give Rest Day!
  }else{
    end_day <- max(x$V1)
    start_day <- min(x$V1)
    
    # 휴점일은 판매실적 데이터(pos) 에서 없는 날짜로 계산되어진다. 
    all_days <- seq(as.Date(start_day), as.Date(end_day), by="day")
    op_days <- unique(x$V1)
    # 판매실적이 아예 없는 날은 휴점일일 것이다. 
    rest_day <- all_days[!all_days %in% op_days]
  }
  
  # before after 3days of rest_day 
  # rest_days <- mapply(c, rest_day - 3, rest_day - 2, rest_day - 1, rest_day + 1, SIMPLIFY = F)
  rest_days <- mapply(c, rest_day - 3, rest_day - 2, rest_day + 1, SIMPLIFY = F)
  # rest_days <- mapply(c, rest_day - 3, rest_day + 1, SIMPLIFY = F)
  
  # dataframe
  df_rest_days <- data.frame(V1 = as.Date(unlist(rest_days), origin = "1970-01-01"), Rest_3day = 1)
  
  return_x <- dplyr::left_join(target_data, df_rest_days)
  return_x$Rest_3day[is.na(return_x$Rest_3day)] <- 0
  print(sum(is.na(return_x)))
  return_x$Rest_3day <- as.factor(return_x$Rest_3day)
  return(return_x)
} 




char_transformation <- function(x, col_name = NULL){
  x$V8 <- as.character(x$V8)
  x$Weekday_Month <- as.character(x$Weekday_Month)
  x$Day_Week <- as.character(x$Day_Week)
  x$Week_Year <- as.character(x$Week_Year)
  x$Kor_Holiday <- as.character(x$Kor_Holiday)
  x$Rest_3day <- as.character(x$Rest_3day)
  return(x)
}


factor_transformation <- function(x, col_name = NULL){
  x$V8 <- as.factor(x$V8)
  x$Weekday_Month <- as.factor(x$Weekday_Month)
  x$Day_Week <- as.factor(x$Day_Week)
  x$Week_Year <- as.factor(x$Week_Year)
  x$Kor_Holiday <- as.factor(x$Kor_Holiday)
  x$Rest_3day <- as.factor(x$Rest_3day)
  return(x)
}


############################### CLUSTER FUNCTIONS #################################

()

subCluster_test <- function(data, test_params){
  
  require(dplyr)
  require(kohonen)
  
  if(is.null(test_params$transformation)) { stop("transformation is null") }
  
  subSet <- data %>% dplyr::group_by(V8) %>% dplyr::summarise_all(test_params$transformation)
  # if all vars same? then sd is NA . replaced it.
  subSet[is.na(subSet)] <- 0 
  cache_df <- subSet
  subSet <- subSet[,names(subSet)[-1]] 
  subSet <- as.matrix(scale(subSet))
  
  # SOM Cluster
  if(is.null(test_params$xdim)){
    som_xdim <- dim(subSet)[2] }else{ som_xdim <- test_params$xdim }
  
  # var 
  somgrid <- kohonen::somgrid(xdim = som_xdim, ydim = test_params$ydim, topo = test_params$topo,
                              neighbourhood.fct = test_params$neighbourhood.fct)
  #
  print("Som Start")
  som_model <- kohonen::som(subSet, grid = somgrid,
                            rlen = 500, alpha = c(0.05, 0.01),
                            keep.data = T)
  
  print(dim(cache_df)[1])
  print(length(som_model$unit.classif))
  
  if(dim(cache_df)[1] != length(som_model$unit.classif)){ stop("Error") }
  
  cache_df$SOM <- som_model$unit.classif
  
  #print("K-Means Start")
  #k_model <- kmeans(subSet, test_params$number_K)
  
  #cache_df$KMEANS <- k_model$cluster
  print("Finish")
  return(cache_df)
}


append_subset_cluster


append_subset_cluster <- function(target_table, cluster_column, cluster_name, ...){
  
  kwargs <- list(...)
  if(is.null(kwargs$test_params)){
    transformation_func <- list(sd = sd)
    test_params <- list("transformation" = transformation_func, "xdim" = 7, "ydim" = 2, 
                        "topo" = "hexagonal", "neighbourhood.fct" = "gaussian")}
  
  else{ test_params <- kwargs$test_params }
  
  subset_table <- target_table[target_table[, cluster_column] == cluster_name,
                               c("V8", "Tot_Sum_Q", "WKD_Q_Index", "WKDay_Q_Index", "WKD_NT_Index", 
                                 "WKD_RT_Index", "Rest_Index", "Holi_Index")]
  
  if(length(unique(subset_table$V8)) == 0){
    #pass
    
  }else{
    #
    subset_table_result <- subCluster_test(subset_table, test_params)
  
    subset_table_key <- subset_table_result[,c("V8", "SOM")]
    subset_table_cluster <- dplyr::left_join(subset_table, subset_table_key, by ="V8")

    subset_table_cluster <- subset_table_cluster %>% 
      dplyr::mutate(PEQ_Cluster = paste0(cluster_name, SOM)) %>% dplyr::select(V8, PEQ_Cluster)

    target_table$PEQ_Cluster[which(target_table$PEQ_Cluster == cluster_name)] <- subset_table_cluster$PEQ_Cluster
    return(target_table)
  }
}



############################## JOINING WEIGHT FUNCTIONS #################################


join_wkYear_dayWeek <- function(order_table, wkd_q_index, dw_q_index, 
                                keys = keys, index_name = index_name){
  require(dplyr)
  
  if(class(wkd_q_index)[1] == "grouped_df"){ wkd_q_index <- wkd_q_index %>% ungroup() }
  if(class(dw_q_index)[1] == "grouped_df"){ dw_q_index <- dw_q_index %>% ungroup() }
  
  # change char 
  wkd_q_index[,keys$key_wkd_q_index] <- lapply(wkd_q_index[,keys$key_wkd_q_index], as.character)
  
  # select V8, Week_Year, Day_Week, WKD_Q_Index 
  wkd_q_index <- wkd_q_index[, append(keys$key_wkd_q_index, index_name$wkd_q_index)]
  
  dw_q_index[,keys$key_dw_q_index] <- lapply(dw_q_index[,keys$key_dw_q_index], as.character)
  
  join_tbl <- dplyr::left_join(order_table, wkd_q_index, by = keys$key_wkd_q_index)
  
  msg <- paste0("[LOG] 1. Append (ORDER_TABLE, WKD_Q_INDEX), by = (", toString(keys$key_wkd_q_index), 
                "), Missing WKD_Q_Index : ", sum(is.na(join_tbl[[index_name$wkd_q_index]])), "\n")
  cat(sprintf(msg))

  join_tbl <- dplyr::left_join(join_tbl, dw_q_index, by = keys$key_dw_q_index)
  
  # 
  join_tbl <- join_tbl %>% dplyr::mutate(WKD_Q_Index = ifelse(is.na(WKD_Q_Index), DW_Q_Index, WKD_Q_Index)) %>% 
    dplyr::select(-DW_Q_Index)
  
  msg <- paste0("[LOG] 1. Append (ORDER_TABLE, DW_Q_INDEX), by = (", toString(keys$key_dw_q_index), 
                "), Missing WKD_Q_Index : ", sum(is.na(join_tbl[[index_name$wkd_q_index]])), "\n")
  cat(sprintf(msg))
  
  msg <- paste0("[LOG] 1. Missing WKD_Q_Index are replace to 0", "\n")
  cat(sprintf(msg))
  
  join_tbl$WKD_Q_Index[which(is.na(join_tbl$WKD_Q_Index))] <- 0
  
  sum(is.na(join_tbl))
  
  msg <- paste0("[LOG] 1. Append Finish with ", sum(is.na(join_tbl)), " missing values", "\n")
  cat(sprintf(msg))
  
  return(join_tbl)
}

##################################################################################

join_wkd_dayWeek <- function(order_table, wkday_index, 
                             keys =keys, index_name = index_name){
  
  require(dplyr)
  
  if(class(wkday_index)[1] == "grouped_df"){ wkday_index <- wkday_index %>% ungroup() }
  
  # change char 
  wkday_index[,keys$key_wkday_index] <- lapply(wkday_index[,keys$key_wkday_index], as.character)
  # select V8, Weekday_Month, WKDay_Q_Index 
  wkday_index <- wkday_index[, append(keys$key_wkday_index, index_name$wkday_q_index)]
  
  join_tbl <- dplyr::left_join(order_table, wkday_index, by = keys$key_wkday_index)
  
  msg <- paste0("[LOG] 2. Append (ORDER_TABLE, WKDay_Q_INDEX), by = (", toString(keys$key_wkday_index), 
                "), Missing WKDay_Q_Index : ", sum(is.na(join_tbl[[index_name$wkday_q_index]])), "\n")
  cat(sprintf(msg))
  
  msg <- paste0("[LOG] 2. Missing WKDay_Q_Index are replace to  ", sum(is.na(join_tbl)), " missing values", "\n")
  cat(sprintf(msg))
  join_tbl$WKDay_Q_Index[which(is.na(join_tbl$WKDay_Q_Index))] <- 0
  
  msg <- paste0("[LOG] 2. Append Finish with ", sum(is.na(join_tbl)), " missing values", "\n")
  cat(sprintf(msg))
  
  return(join_tbl)
  
}


##################################################################################

join_wkYear_dayWeek_ntran <- function(order_table, wk_ntran, dw_ntran,
                                      keys = keys, index_name = index_name){
  
  require(dplyr)
  if(class(wk_ntran)[1] == "grouped_df"){ wk_ntran <- wk_ntran %>% ungroup() }
  if(class(dw_ntran)[1] == "grouped_df"){ dw_ntran <- dw_ntran %>% ungroup() }
  
  wk_ntran[,keys$key_wkd_q_index] <- lapply(wk_ntran[,keys$key_wkd_q_index], as.character)
  # select V8, Week_Year, Day_Week, WKD_NT_Index 
  wk_ntran <- wk_ntran[, append(keys$key_wkd_q_index, index_name$wkd_nt_index)]
  
  dw_ntran[,keys$key_dw_q_index] <- lapply(dw_ntran[,keys$key_dw_q_index], as.character)
  
  join_tbl <- dplyr::left_join(order_table, wk_ntran, by = keys$key_wkd_q_index)
  
  msg <- paste0("[LOG] 3. Append (ORDER_TABLE, WKD_NTRAN_INDEX), by = (", toString(keys$key_wkd_q_index), 
                "), Missing WKD_NT_Index : ", sum(is.na(join_tbl[[index_name$wkd_nt_index]])), "\n")
  cat(sprintf(msg))
  
  join_tbl <- dplyr::left_join(join_tbl, dw_ntran, by = keys$key_dw_q_index)
  
  join_tbl <- join_tbl %>% 
    dplyr::mutate(WKD_NT_Index = ifelse(is.na(WKD_NT_Index), DW_NTRAN_Index, WKD_NT_Index)) %>% 
    dplyr::select(-DW_NTRAN_Index)
  
  msg <- paste0("[LOG] 3. Append (ORDER_TABLE, DW_NTRAN_Index), by = (", toString(keys$key_dw_q_index), 
                "), Missing WKD_NT_Index : ", sum(is.na(join_tbl[[index_name$wkd_nt_index]])), "\n")
  cat(sprintf(msg))
  
  msg <- paste0("[LOG] 3. Missing WKD_NT_Index are replace to 0", "\n")
  cat(sprintf(msg))
  
  join_tbl$WKD_NT_Index[which(is.na(join_tbl$WKD_NT_Index))] <- 0
  
  msg <- paste0("[LOG] 3. Append Finish with ", sum(is.na(join_tbl)), " missing values", "\n")
  cat(sprintf(msg))
  
  return(join_tbl)
}

##################################################################################

join_wkYear_dayWeek_rtran <- function(order_table, wk_rtran, dw_rtran,
                                      keys = keys, index_name = index_name){
  require(dplyr)
  
  if(class(wk_rtran)[1] == "grouped_df"){ wk_rtran <- wk_rtran %>% ungroup() }
  if(class(dw_rtran)[1] == "grouped_df"){ dw_rtran <- dw_rtran %>% ungroup() }
  
  wk_rtran[,keys$key_wkd_q_index] <- lapply(wk_rtran[,keys$key_wkd_q_index], as.character)
  # select V8, Week_Year, Day_Week, WKD_NT_Index 
  wk_rtran <- wk_rtran[, append(keys$key_wkd_q_index, index_name$wkd_rt_index)]
  dw_rtran[,keys$key_dw_q_index] <- lapply(dw_rtran[,keys$key_dw_q_index], as.character)
  
  join_tbl <- dplyr::left_join(order_table, wk_rtran, by = keys$key_wkd_q_index)
  
  msg <- paste0("[LOG] 4. Append (ORDER_TABLE, WKD_RTRAN_INDEX), by = (", toString(keys$key_wkd_q_index), 
                "), Missing WKD_NT_Index : ", sum(is.na(join_tbl[[index_name$wkd_rt_index]])), "\n")
  cat(sprintf(msg))
  
  join_tbl <- dplyr::left_join(join_tbl, dw_rtran, by = keys$key_dw_q_index)
  
  join_tbl <- join_tbl %>% 
    dplyr::mutate(WKD_RT_Index = ifelse(is.na(WKD_RT_Index), DW_RTRAN_Index, WKD_RT_Index)) %>% 
    dplyr::select(-DW_RTRAN_Index)
  
  msg <- paste0("[LOG] 4. Append (ORDER_TABLE, DW_RTRAN_Index), by = (", toString(keys$key_dw_q_index), 
                "), Missing WKD_RT_Index : ", sum(is.na(join_tbl[[index_name$wkd_rt_index]])), "\n")
  cat(sprintf(msg))
  
  msg <- paste0("[LOG] 4. Missing WKD_RT_Index are replace to 0", "\n")
  cat(sprintf(msg))
  
  join_tbl$WKD_RT_Index[which(is.na(join_tbl$WKD_RT_Index))] <- 0
  #join_tbl[[index_name$wkd_rt_index]][which(is.na(join_tbl[[index_name$wkd_rt_index]]))] <- 0
  
  msg <- paste0("[LOG] 4. Append Finish with ", sum(is.na(join_tbl)), " missing values", "\n")
  cat(sprintf(msg))
  
  return(join_tbl)
}


##################################################################################


join_rd_hd_index <- function(order_table, rd_index, hd_index,
                             keys = keys, index_name = index_name){
  require(dplyr)
  
  if(class(rd_index)[1] == "grouped_df"){ rd_index <- rd_index %>% ungroup() }
  if(class(hd_index)[1] == "grouped_df"){ hd_index <- hd_index %>% ungroup() }
  
  rd_index[, keys$key_rd_index] <- lapply(rd_index[, keys$key_rd_index], as.character)
  rd_index <- rd_index[, append(keys$key_rd_index, index_name$rd_index)]
  join_tbl <- dplyr::left_join(order_table, rd_index, by = keys$key_rd_index)
  
  msg <- paste0("[LOG] 5. Append RD_Index with ", sum(is.na(join_tbl)), " missing values", "\n")
  cat(sprintf(msg))
  
  join_tbl$Rest_Index[which(is.na(join_tbl$Rest_Index))] <- 0
  
  msg <- paste0("[LOG] 5. Missing WKD_RT_Index are replace to 0", "\n")
  cat(sprintf(msg))
  
  ################# holiday index ##############
  
  hd_index[,keys$key_hd_index] <- lapply(hd_index[,keys$key_hd_index], as.character)
  hd_index <- hd_index[, append(keys$key_hd_index, index_name$hd_index)]
  join_tbl <- dplyr::left_join(join_tbl, hd_index, by = keys$key_hd_index)
  
  msg <- paste0("[LOG] 6. Append HD_Index with ", sum(is.na(join_tbl)), " missing values", "\n")
  cat(sprintf(msg))
  
  join_tbl$Holi_Index[which(is.na(join_tbl$Holi_Index))] <- 0
  
  msg <- paste0("[LOG] 6. Missing HD_Index are replace to 0", "\n")
  cat(sprintf(msg))
  
  return(join_tbl)
}


weight_table

cluster_table_1049 %>% group_by(PEQ_Cluster) %>% summarise(N = n()) %>% print(n=500)


train_params_1049






############################### TRAINING FUNCTIONS #################################


#RMSE
rmse <- function(real, pred){
  e <- (real - pred)
  return(sqrt(mean(e^2)))
}


# train/validation split by SKU above 10 
train_valid_split_by_sku <- function(x, train_ratio){
  
  require(dplyr)
  
  temp <- dplyr::left_join(x, 
                           x %>% dplyr::group_by(V8) %>% dplyr::summarise(N = n()) %>% 
                             dplyr::filter(N > 10) %>% 
                             dplyr::select(V8) %>% dplyr::mutate(Ix = 1), by = 'V8')
  temp <- temp %>% 
    dplyr::filter(Ix == 1) %>% 
    dplyr::select(V1, V8) %>%
    dplyr::rowwise() %>%
    dplyr::mutate(Group = sample(
      c("train", "test"),
      1,
      replace = TRUE,
      prob = c(train_ratio, 1-train_ratio)
    ))
  
  return_df <- dplyr::left_join(x, temp, by = c("V1", "V8"))
  return_df$Group[is.na(return_df$Group)] <- "train"
  
  train <- return_df[return_df$Group == "train", ]
  test <- return_df[return_df$Group == "test", ]
  train$Group <- NULL
  test$Group <- NULL
  
  return(list("train" = train, "test" = test))
}



column_check <- function(input_df, compare_list){
  # function documentation-- 
  col_name <- setdiff(compare_list, names(input_df))
  if(length(col_name) > 0){
    msg <- paste("[Data Error] 입력데이터 중 '", col_name, "' Column(Feature)이 없습니다.", sep="")
    stop(msg)
  }
}


list_check <- function(x){
  # function documentation--
  file_name <- substitute(x)
  if(!typeof(x) == "list"){
    msg <- paste("[Input Error] '",file_name,"'은 리스트 형태여야 합니다.", sep="")
    stop(msg)
  }
}


set_training_columns <- function(target_name, feature_list){
  target_idx <- grep(target_name, feature_list)
  if(length(target_idx) == 0){  # there's no Target Column
    basic_features <- append(feature_list, target_name)
    return(basic_features)
  }else{ # there's already exist target column so it moves to last. 
    non_target_idx <- setdiff(1:length(feature_list), target_idx)
    basic_features <- append(feature_list[non_target_idx], feature_list[target_idx])
    return(basic_features)
  }
}



train_xgb_model_v1 <- function(data_list, model_params, ...){
  # function documentation --
  kwargs <- list(...)
  
  if(is.null(kwargs$verbose)){ verbose <- FALSE }
  else{ verbose <- kwargs$verbose }

  result_df <- list()
  
  # set basic working directory and loading packages
  # setwd("~/R/e-poc-regression")  
  require(xgboost)
  require(dplyr)
  require(dummy)
  require(lubridate)
  cat(sprintf("[LOG] 필수 패키지 로드 완료\n"))
  
  
  # input parameter type check 
  list_check(data_list); list_check(model_params)
  
  if(!dim(data_list$train)[2] == dim(data_list$test)[2]){
    stop("[Data Error] 입력데이터 중 Train/Test dataset featrues 수가 다릅니다")
  }
  cat(sprintf("[LOG] 입력변수 확인 완료 \n"))
  
  # create directory 
  wk_path <- file.path(getwd(), model_params$version)
  dir.create(wk_path, showWarnings = FALSE) 
  
  result_file_path = file.path(wk_path, 'xgb-results/')
  model_save_path = file.path(wk_path, 'xgb-models/')
  
  dir.create(result_file_path, showWarnings = FALSE) 
  dir.create(model_save_path, showWarnings = FALSE)
  
  msg = paste("[LOG] ", wk_path,"에 'xgb-result', 'xgb-model' 폴더 생성 완료\n", sep="")
  cat(sprintf(msg))
  
  # Column Setting and Check
  if(!model_params$dynamic_features){
    
    basic_features <- set_training_columns(model_params$target, model_params$features)
    cat(sprintf("[LOG] Non-Cluster and Non-dynamic features model training \n"))
    
    # column check 
    column_check(data_list$train, basic_features)
    
    # model training 
    result_df[[1]] <- model_training(train = data_list$train[,basic_features], 
                                     test  = data_list$test[,basic_features],
                                     train_parameter = model_params$train_parameter,
                                     exclude_features = model_params$exclude_one_hot_features, cluster = NULL, 
                                     model_save_path = model_save_path, result_file_path = result_file_path,
                                     str_code = model_params$str_code,
                                     target = model_params$target, cache_features = kwargs$cache_features,
                                     verbose = kwargs$verbose, write_the_result = kwargs$write_the_result)
    
  }else{ 
    # Dynamic features
    if(!model_params$same_features){
      if(!length(model_params$clusters) == length(model_params$features)){
        stop("[Data Error] 클러스터의 수가 서로 다릅니다.")
      }
    }
    
    cat(sprintf("[LOG] Cluster and Dynamic features model training\n"))
    
    for(i in 1:length(model_params$clusters)){
      
      cluster_name <- as.character(model_params$clusters[i])
      
      # same features
      if(model_params$same_features){
        basic_features <- set_training_columns(model_params$target, model_params$features)
        column_check(data_list$train, basic_features)
        exclude_feature <-  model_params$exclude_one_hot_feature
        }
      else{
        cluster_features <- model_params$features[[cluster_name]]
        list_check(cluster_features)
        include_feature <- cluster_features$include
        exclude_feature <- cluster_features$exclude
        basic_features <- set_training_columns(model_params$target, include_feature)
        # column check
        column_check(data_list$train, basic_features)
      }

      # data Split by Clusters
      train <- data_list$train[which(data_list$train[, model_params$cluster_column] == cluster_name), ]
      test <- data_list$test[which(data_list$test[, model_params$cluster_column] == cluster_name), ]
      
      # Model Training
      result_df[[i]] <-model_training(train = train[, basic_features],
                                      test = test[, basic_features],
                                      train_parameter = model_params$train_parameter,
                                      exclude_features = exclude_feature, cluster = cluster_name,
                                      model_save_path = model_save_path, result_file_path = result_file_path,
                                      str_code = model_params$str_code,
                                      target = model_params$target, cache_features = kwargs$cache_features,
                                      verbose = kwargs$verbose, write_the_result = kwargs$write_the_result)
      
    }
  }
  msg <- paste("[SUCCESS] Model Train Complete. Path : ", model_save_path, " \n", sep = "")
  cat(sprintf(msg))
  if(verbose){
    result_data <- do.call(rbind, result_df)
    return(result_data)
  }else{
    return(0)
  }
}



# model training
model_training <- function(train, test, train_parameter, ...){
  kwargs <- list(...)
  
  if(is.null(kwargs$exclude_features)){ exclude_features <- NULL}
  else{ exclude_features <- kwargs$exclude_features }
  
  if(is.null(kwargs$cluster)){ cluster <- "NONE" }
  else{ cluster <- kwargs$cluster }
  
  if(is.null(kwargs$verbose)){ verbose <- FALSE }
  else{ verbose <- kwargs$verbose }
  
  if(verbose){ 
    cat(sprintf("[LOG] Cache ON \n"))
    if(is.null(kwargs$cache_features)){ 
      # basic cache header
      cache_header <- c("V1", "V8")
    }else{
      # given cache header
      cache_header <- kwargs$cache_features
    }
    column_check(test, cache_header)
    cache_df <- test[, cache_header]
  }
  
  if(is.null(kwargs$model_save_path)){ model_save_path = getwd() }
  else{ model_save_path = kwargs$model_save_path }
  
  if(is.null(kwargs$str_code)){ str_code <- "NONE" }
  else{ str_code <- kwargs$str_code }
  
  if(is.null(kwargs$target)){
    cat(sprintf("[LOG] Target is automatically set (nSum_Q) \n"))
    target <- "nSum_Q"
  }else{
    target <- kwargs$target
  }
  
  # function documentation --
  if(cluster == "NONE"){
    cat(sprintf("[LOG] Start Whole-Model Training (Non-Clusters) \n"))
  }else{
    msg <- paste("[LOG] Start ", cluster, " Model Training \n", sep="")
    cat(msg)
  }
  
  # Remove meaningless features
  train <- train[, -which(names(train) %in% exclude_features)]
  
  # Extract category-info
  category_info <- dummy::categories(x=train, p="all")
  train_dum <- dummy::dummy(x=train, object = category_info, int = TRUE, verbose = FALSE)
  test_dum <- dummy::dummy(x=test, object = category_info, int = TRUE, verbose = FALSE)
  
  category_features <- names(category_info)  
  numeric_features <- names(train[, -which(names(train) %in% category_features)])
  
  x_train <- dplyr::bind_cols(train_dum, train[, numeric_features])
  x_test <- dplyr::bind_cols(test_dum, test[, numeric_features])
  
  # Transform dtrain(Xgb) data
  train_target_idx <- grep(target, names(x_train))
  test_target_idx <- grep(target, names(x_test))
  
  # Modify
  dtrain <- xgb.DMatrix(data = as.matrix(sapply(x_train[,-train_target_idx], as.numeric )), 
                        label = as.matrix(sapply(x_train[, train_target_idx], as.numeric)))
  
  dtest <- xgb.DMatrix(data = as.matrix(sapply(x_test[,-test_target_idx], as.numeric)), 
                       label = as.matrix(sapply(x_test[, test_target_idx], as.numeric)))
  
  watchlist <- list(train = dtrain, eval = dtest)
  
  xgb_model <- xgb.train(data = dtrain,  
                         max.depth = train_parameter$max.depth,
                         eta = train_parameter$eta, 
                         nthread = train_parameter$nthread, 
                         nrounds = train_parameter$nrounds, 
                         watchlist = watchlist, 
                         eval.metric = train_parameter$eval.metric,
                         #feval =cust_multiple_loss,
                         maximize = train_parameter$maximize,
                         print_every_n = 10, 
                         early_stopping_rounds = train_parameter$early_stopping_rounds,
                         seed = round(runif(1)*1000))
  # evaluation results     
  train_rmse <- xgb_model$best_score   
  
  pred <- predict(xgb_model, as.matrix(x_test[,-test_target_idx]))
  pred <- round(pred)
  
  # result file save
  model_name <- paste(model_save_path, "xgb-model-", str_code, "-", target, "-", cluster, sep = "")
  category_name <- paste(model_save_path, "category-info-", str_code, "-", target, "-", cluster, sep = "")
  
  # xgb.save
  saveRDS(xgb_model, model_name)
  saveRDS(category_info, category_name)
  
  #
  if(!is.null(kwargs$write_the_result)){
    if(!is.null(kwargs$result_file_path)){
      msg <- paste("[LOG] (Under-Const) Writing evaluation result. Path : ", kwargs$result_file_path, " \n", sep = "")
      cat(sprintf(msg))
    }
  }
  
  if(verbose){
    cache_df$real <- x_test[,ncol(x_test)]
    cache_df$pred <- pred 
    return(cache_df)
  }
}


################################ INFERENCE FUNCTIONS #############################


inference_model_v1 <- function(order_table, weight_tables, cluster_table, 
                               inference_params, ...){
  
  require(xgboost)
  
  kwargs <- list(...)
  
  if(is.null(kwargs$keys)){
    keys <- list(
      "key_wkd_q_index" =  c("V8", "Week_Year", "Day_Week"),
      "key_dw_q_index" = c("V8", "Day_Week"),
      "key_wkday_index" = c("V8", "Weekday_Month"),
      "key_rd_index" = c("V8", "Rest_3day"),
      "key_hd_index" = c("V8", "Kor_Holiday"))
  }else{
    keys <- kwargs$keys
  }
  if(is.null(kwargs$index_name)){
    index_name <- list(
      "wkd_q_index" = "WKD_Q_Index",
      "dw_q_index" = "DW_Q_Index",
      "wkday_q_index" = "WKDay_Q_Index",
      "wkd_nt_index" = "WKD_NT_Index",
      "wkd_rt_index" = "WKD_RT_Index",
      "rd_index" = "Rest_Index",
      "hd_index" = "Holi_Index")
  }else{
    index_name <- kwargs$index_name
  }
  
  # 1. Parameter Check
  list_check(inference_params)
  
  # 2. Exclude Rest day in Order Table
  rest_day <- as.Date(inference_params$str_params$rest_day)
  order_table <- order_table[!order_table$V1 %in% rest_day, ]
  
  # 3. Day Information Calculator 
  order_table <- calculate_time_variable_v2(order_table)
  order_table <- before_after_3days_of_restday_v2(order_table, order_table, rest_day)
  
  # factor transformation
  order_table <- char_transformation(order_table)
  
  # 4. Join Weight Matrix by (SKU_CODE, Week)
  order_table <- join_wkYear_dayWeek(order_table, weight_tables$WKD_Q_INDEX, 
                                     weight_tables$DW_Q_INDEX, keys, index_name)
  # 4.2 
  order_table <- join_wkd_dayWeek(order_table,  weight_tables$WKDay_INDEX,
                                  keys = keys, index_name = index_name)
  # 4.3
  order_table <- join_wkYear_dayWeek_ntran(order_table, weight_tables$WK_NTRAN_INDEX, 
                                           weight_tables$DW_NTRAN_INDEX, 
                                           keys = keys, index_name = index_name)
  # 4.4
  order_table <- join_wkYear_dayWeek_rtran(order_table, weight_tables$WK_RTRAN_INDEX,
                                           weight_tables$DW_RTRAN_INDEX,
                                           keys = keys, index_name = index_name)
  # 4.5 
  order_table <- join_rd_hd_index(order_table, weight_tables$RD_INDEX, 
                                  weight_tables$HD_INDEX, keys = keys, index_name = index_name)
  
  msg <- paste0("[LOG] WEIGHT MATRIX APPEND COMPLETE WITH ", sum(is.na(order_table)), " MISSING VALUES", "\n")
  print(msg)  
  
  # 5. Join Clusters 
  cluster_table$V8 <- as.character(cluster_table$V8)
  input_x <- dplyr::left_join(order_table, cluster_table, by = c("V8"))
  print("Input data NA check"); print(sum(is.na(input_x)))
  # Make input . fin 
  
  print(dim(input_x))
  
  # 6. Change Types
  input_x <- factor_transformation(input_x)
  
  # inference by clusters
  result_df_list <- xgb_infenrece(data = input_x, str_code = inference_params$str_params$str_code, 
                                  clusters = inference_params$clusters,
                                  cluster_column_name = inference_params$cluster_column,
                                  version = inference_params$version,
                                  target = "Tot_Sum_Q")
  
  result_data <- do.call(rbind, result_df_list)
  return(result_data)
}




# function
xgb_infenrece <- function(data, str_code, clusters, cluster_column_name, ...){
  
  kwargs <- list(...)
  #list_check(clusters)
  column_check(data, cluster_column_name)
  if(is.null(kwargs$version)){ version <- "public_v1" }
  else{ version <- kwargs$version }
  if(is.null(kwargs$base_path)){ 
    wk_path <-  file.path(getwd(), version)} 
  else{ "/user/path/" }
  if(is.null(kwargs$target)){ target <- "Tot_Sum_Q" }
  else{ target <- kwargs$target }
  
  # hold params
  result_df <- list()
  model_save_path <- file.path(wk_path, 'xgb-models/')
  save_path <- file.path(wk_path, 'xgb-inference/')
  dir.create(save_path, showWarnings = FALSE) 
  
  # Search model & category rds file list in case of matching STR_CODE
  str_models <- list.files(path=model_save_path, pattern = str_code)
  # Search model & category rds file list in 'str_models' with mathcing Target
  target_models <- str_models[grep(target, str_models)]
  
  # for loop?
  for(i in 1:length(clusters)){
    
    cat(sprintf("Target : %s, %s/%s-th Cluster : %s 예측 시작\n",
                target, i, length(clusters), clusters[i]))
    cluster_name <- as.character(clusters[i])
    
    # split data into clusters
    inf_one_cluster_data <- data[which(data[, cluster_column_name] == cluster_name), ]
    
    if(length(unique(inf_one_cluster_data$V8)) == 0){
      # pass loop
      # 예측대상 상품 자체가 클러스터에 존재하지 않는 경우.
      msg <- paste0("[PASS] There's no SKUS in ", cluster_name, "\n")
      cat(sprintf(msg))
      
    }else{
      # cache for result 
      cache_data <- inf_one_cluster_data
      inf_one_cluster_data <- subset(inf_one_cluster_data, select = -c(V1, PEQ_Cluster))
      
      # get trained model, category rds file from 'target_models'
      m_model <- target_models[grep(paste0("\\b",cluster_name,"\\b"), target_models)]
      trained_model_name <- m_model[grep("xgb-model", m_model)]
      trained_cat_info_name <- m_model[grep("category-info", m_model)]
      model_path <- paste0(model_save_path, trained_model_name)
      category_info_path <- paste0(model_save_path, trained_cat_info_name)
      
      # get each Instance (Binaries)
      # get Category_Info
      trained_category_info <- readRDS(category_info_path)
      
      # get Xgb Model
      saved_model <- readRDS(model_path)
      trained_xgb_model <- xgb.Booster.complete(saved_model)
      
      # make DMatrix
      inf_one_dummy <- dummy::dummy(x=inf_one_cluster_data, 
                                    object = trained_category_info, int = TRUE, verbose = FALSE)
      category_features <- names(trained_category_info)  
      numeric_features <- names(inf_one_cluster_data[, -which(names(inf_one_cluster_data) %in% category_features)])
      inf_data <- dplyr::bind_cols(inf_one_dummy, inf_one_cluster_data[, numeric_features])
      dtest <- xgb.DMatrix(as.matrix(sapply(inf_data, as.numeric)))
      
      # Prediction (or Inference)
      pred <- predict(trained_xgb_model, dtest)
      pred <- round(pred)
      
      cache_data$real <- NA
      cache_data$pred <- pred
      
      result_df[[i]] <- cache_data
    }
  }
  return(result_df)
}







